[2021.04.24] pretrain:
    1. 【不要sbn】：lr=[0.01 0.02 0.03] 情况下都是：nbn.loss高 finetune.acc也高，sbn.loss低，finetune.acc也低
    2. 【pret lr过小，则eval不适应大lr】：从0.01到0.03一直涨点； 0.01-0.02的涨幅比0.02-0.03的涨幅更大；三个cfg下pretrain的loss都是3.7-3.9，但是lnr_eval loss movavg依次是150、50、10，这说明pretrain的lr如果过小，那eval的时候就会很不适应大lr！
    3. 【目前最好】：综上nbn>sbn；lr0.03>ot；mo .99略好于.995远好于.999；t0.2略好于0.1远好于0.07
    4. 【下一步】：最好的baseline是nbn_lr0.03_vlr5_m0.99_t0.2；那么从两个方向尝试，1是继续增大pret lr，2是grid sea lnr_eval HP

[2021.04.25] finetune:
    1. 【上次实验】：之前最好是nbn_lr0.03_vlr5_m0.99_t0.2 是 72.96，现在最好是 nbn_lr0.05_vlr2 是 79.60
    2. 【上次实验tb】：看起来好的ckpt，只要finetune 1ep 就出来优劣保序到finetune完毕了；这个性质非常好，说明1步step甚至也保序的；又回过头看了CIFAR RRC，结论基本一致，但CIFAR 噪声比较大，保序性没有那么强，但对于final performance 差>1个点的时候还是可以明确分出来的。

            【！！！IDEA IDEA IDEA ！！！】那么有一个idea是自适应比较？如果多次比较的排名在变就适度多finetune几个step？auto自适应finetune？

    3. 【pret lr过小，则eval不适应大lr】：从0.01-0.02-0.03-0.05一直稳定涨点，pret loss轻微递减，然而lev loss显著下降。因此目前还是应该进一步增大pret lr
    4. 【bs增大会轻微变差】：差大概0.5，不过为了速度可以牺牲？
    5. 【vlr】：目前感觉plr0.03不用看了因为v loss都到几十了；在plr0.05的时候，vlr从2到5到10 20 30，性能一直在变差，v loss也一直在升；但是大bs的时候反而喜欢大vlr
    6. 【目前最好】b128：nbn_lr0.05_vlr2 是 79.60     b256：nbn_lr0.1_vlr20 是 79.20
    7. 【下一步】：为了妥协速度（16h vs 9h），使用b256；  b256 是喜欢大pretlr、大vlr，因此从这两个方向尝试

[2021.04.25] finetune:
    1. 【b128】：之前最好是 nbn_lr0.05_vlr2 是 79.60，现在最好是 200ep_b128_nbn_lr0.1_vlr2 是 82.88。增大 lr 仍然带来gain。另外，vlr=1比=2要差
    2. 【b256】：vlr影响其实不大，20 or 30就行；lr越大的话vloss越低vacc越高。最好是 imn50_b256/200ep_b256_nbn_lr0.4_vlr20
    3. 【下一步】：vlr影响不大了，继续调大lr，0.5 0.6 1.0 就这仨了！然后 vlr 是 10 20 30
    4. 【sh40】：当lr=0.4 or 0.5的时候，sh40的行为非常奇怪，在初期会进入loss高原震荡导致后期很差；考虑测试：①不warmup ②不grad_clip ③都不。结果发现 ①比原实验更差 ②比原来好 ③比原来好。可能warmup还是必须的？
    5. 【train_loss_ep和train_loss特别不一致】：这两个东西，一个是均值，一个是最近一次的值；为何数量级差距这么大？是因为第一个iter的loss炸了吗？
